{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Modelo de deep learning Fake News\n",
        "El presente modelo, se genera a partir de dos bases de datos, la primera denominada 'fake' y la segunda 'real'. La recolección de información, se hizo a partir de las noticias al rededor del entonces candidato Donald Trump en la carrera por la presidencia de Estados Unidos en el año 2016.\n",
        "Base de datos disponible en:\n",
        "https://www.kaggle.com/datasets/algord/fake-news\n",
        "\n",
        "*Por: Israel Sánchez Graciano*"
      ],
      "metadata": {
        "id": "ZFWwkaVkgqFp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIwlLUOfEHU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89529876-8650-4587-d015-46f8a25e6589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "cqEM1LF_RWp7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_YR56-2SiVE",
        "outputId": "ddbeaf57-200f-4094-c3a7-e9c32ac570c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Carga de bases de datos\n",
        "df_true = pd.read_csv(\"/content/drive/MyDrive/Proyect 1 /true.csv\")\n",
        "df_fake = pd.read_csv(\"/content/drive/MyDrive/Proyect 1 /fake.csv\")\n",
        "\n",
        "df_true[\"label\"] = 1\n",
        "df_fake[\"label\"] = 0"
      ],
      "metadata": {
        "id": "LlR78V_uuw9j"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Encabezado\n",
        "df_true[\"text\"] = df_true[\"title\"] + \" \" + df_true[\"text\"]\n",
        "df_fake[\"text\"] = df_fake[\"title\"] + \" \" + df_fake[\"text\"]\n"
      ],
      "metadata": {
        "id": "zXeabayqvOxC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Balance del dataset: 2500 noticias de cada clase\n",
        "df_true_sample = df_true.sample(n=2500, random_state=42)\n",
        "df_fake_sample = df_fake.sample(n=2500, random_state=42)\n",
        "df_sample = pd.concat([df_true_sample, df_fake_sample]).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "#Limpieza de texto\n",
        "def limpiar_texto(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'\\W', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "df_sample[\"text\"] = df_sample[\"text\"].apply(limpiar_texto)"
      ],
      "metadata": {
        "id": "NMB5y5W_vWWF"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Tokenizar\n",
        "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df_sample[\"text\"])\n",
        "sequences = tokenizer.texts_to_sequences(df_sample[\"text\"])\n",
        "\n",
        "max_length = 250\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "labels = df_sample[\"label\"].values"
      ],
      "metadata": {
        "id": "heBdnLe2vZgO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Glove\n",
        "embedding_index = {}\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Proyect 1 /glove.6B.100d.txt\", encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_index[word] = vector\n",
        "\n",
        "embedding_dim = 100\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(5000, len(word_index) + 1)\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i >= 5000:\n",
        "        continue\n",
        "    embedding_vector = embedding_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "zs4GE9tKvdAl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelo\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=num_words,\n",
        "              output_dim=embedding_dim,\n",
        "              weights=[embedding_matrix],\n",
        "              input_length=max_length,\n",
        "              trainable=True),  # Entrenable\n",
        "    Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "zXDTO2mDudWR",
        "outputId": "8b4e8144-dab2-417f-db53-edee18681dd7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │       \u001b[38;5;34m500,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">500,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m500,000\u001b[0m (1.91 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">500,000</span> (1.91 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m500,000\u001b[0m (1.91 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">500,000</span> (1.91 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento\n",
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    epochs=10,\n",
        "                    batch_size=64)\n",
        "\n",
        "# Evaluación del modelo\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHInxDEOvqnT",
        "outputId": "b9de9d58-2ac8-47c2-aedc-b7091a59b530"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 2s/step - accuracy: 0.7509 - loss: 0.5058 - val_accuracy: 0.9250 - val_loss: 0.1868\n",
            "Epoch 2/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - accuracy: 0.9277 - loss: 0.1860 - val_accuracy: 0.9460 - val_loss: 0.1499\n",
            "Epoch 3/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 2s/step - accuracy: 0.9557 - loss: 0.1327 - val_accuracy: 0.9560 - val_loss: 0.1341\n",
            "Epoch 4/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 2s/step - accuracy: 0.9612 - loss: 0.1058 - val_accuracy: 0.9570 - val_loss: 0.1184\n",
            "Epoch 5/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.9751 - loss: 0.0743 - val_accuracy: 0.9440 - val_loss: 0.1706\n",
            "Epoch 6/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 2s/step - accuracy: 0.9791 - loss: 0.0606 - val_accuracy: 0.9650 - val_loss: 0.1149\n",
            "Epoch 7/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 2s/step - accuracy: 0.9871 - loss: 0.0356 - val_accuracy: 0.9640 - val_loss: 0.1159\n",
            "Epoch 8/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 2s/step - accuracy: 0.9849 - loss: 0.0440 - val_accuracy: 0.9650 - val_loss: 0.1168\n",
            "Epoch 9/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 2s/step - accuracy: 0.9901 - loss: 0.0257 - val_accuracy: 0.9660 - val_loss: 0.1328\n",
            "Epoch 10/10\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 2s/step - accuracy: 0.9944 - loss: 0.0175 - val_accuracy: 0.9650 - val_loss: 0.1479\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 305ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.96       490\n",
            "           1       0.96      0.97      0.97       510\n",
            "\n",
            "    accuracy                           0.96      1000\n",
            "   macro avg       0.97      0.96      0.96      1000\n",
            "weighted avg       0.97      0.96      0.96      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prueba del modelo\n",
        "X_train_texts, X_test_texts, _, _ = train_test_split(df_sample[\"text\"], labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    texto = X_test_texts.iloc[i]\n",
        "    secuencia = tokenizer.texts_to_sequences([texto])\n",
        "    padded = pad_sequences(secuencia, maxlen=max_length, padding='post')\n",
        "    pred = model.predict(padded)[0][0]\n",
        "\n",
        "    etiqueta_real = y_test[i]\n",
        "    etiqueta_predicha = 1 if pred > 0.5 else 0\n",
        "\n",
        "    print(f\"\\n📰 Noticia: {texto[:200]}...\")\n",
        "    print(f\"🔹 Real: {etiqueta_real} | 🔸 Predicha: {etiqueta_predicha} ({'REAL' if etiqueta_predicha==1 else 'FAKE'}) - Confianza: {pred:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P92oifwF8bmN",
        "outputId": "66f6ac2b-06d9-4365-af85-97de303a594a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 820ms/step\n",
            "\n",
            "📰 Noticia: trump says nothing is off the table for response to iran washington reuters president donald trump told reporters on thursday said nothing is off the table in terms of a response to iran s ballistic m...\n",
            "🔹 Real: 1 | 🔸 Predicha: 1 (REAL) - Confianza: 1.00\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
            "\n",
            "📰 Noticia: chinese general kills himself amid corruption probe beijing reuters a prominent chinese general under investigation for corruption has committed suicide state media said on tuesday the latest developm...\n",
            "🔹 Real: 1 | 🔸 Predicha: 1 (REAL) - Confianza: 1.00\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
            "\n",
            "📰 Noticia: the state that gets more refugees than any other in america may surprise you here s one sure way to turn a solidly red state blue in fiscal year 2014 texas resettled 7 234 refugees however that doesn ...\n",
            "🔹 Real: 0 | 🔸 Predicha: 0 (FAKE) - Confianza: 0.00\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 957ms/step\n",
            "\n",
            "📰 Noticia: as republican tax vote nears more senators waver washington reuters president donald trump s drive to win passage of a sweeping republican tax bill in the u s congress hit potential obstacles on thurs...\n",
            "🔹 Real: 1 | 🔸 Predicha: 1 (REAL) - Confianza: 1.00\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754ms/step\n",
            "\n",
            "📰 Noticia: power crews scramble to puerto rico after maria smashes its grid new york reuters utility crews from the u s mainland were scrambling to puerto rico on thursday after hurricane maria left nearly the e...\n",
            "🔹 Real: 1 | 🔸 Predicha: 1 (REAL) - Confianza: 1.00\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step\n",
            "\n",
            "📰 Noticia: you re hired how this brilliant surgeon will destroy obama s legacy video ben carson says he s still ironing out his role in the incoming administration of president elect donald trump but one thing s...\n",
            "🔹 Real: 0 | 🔸 Predicha: 0 (FAKE) - Confianza: 0.00\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
            "\n",
            "📰 Noticia: mike huckabee scorches the press grow up start acting like journalists video...\n",
            "🔹 Real: 0 | 🔸 Predicha: 0 (FAKE) - Confianza: 0.00\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step\n",
            "\n",
            "📰 Noticia: republican grassley to ask trump jr to testify to senate panel cnn washington reuters senate judiciary committee chairman charles grassley a republican planned to send a letter on thursday to donald t...\n",
            "🔹 Real: 1 | 🔸 Predicha: 1 (REAL) - Confianza: 1.00\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 584ms/step\n",
            "\n",
            "📰 Noticia: singaporean blogger released after winning u s ruling for asylum chicago reuters a young singaporean blogger who says he was persecuted for his political opinions in the southeast asian country was re...\n",
            "🔹 Real: 1 | 🔸 Predicha: 1 (REAL) - Confianza: 1.00\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536ms/step\n",
            "\n",
            "📰 Noticia: congress watchdog to investigate trump voter fraud panel washington reuters the u s congress watchdog office has agreed to investigate president donald trump s commission on voter fraud after three de...\n",
            "🔹 Real: 1 | 🔸 Predicha: 1 (REAL) - Confianza: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusión\n",
        "Se eligió una red neuronal recurrente del tipo LSTM bidireccional debido a su capacidad para capturar relaciones de dependencia a largo plazo en secuencias de texto, lo cual es esencial para entender el contexto de una noticia.\n",
        "\n",
        "Los embeddings preentrenados GloVe se usaron para representar palabras en un espacio semántico denso. Estos embeddings permiten al modelo entender similitudes semánticas entre palabras, incluso si no se han visto en el entrenamiento.\n",
        "\n",
        "La red logró un 96% de precisión en la clasificación de noticias verdaderas y falsas, demostrando ser una solución efectiva al problema de detección de fake news\n",
        "\n"
      ],
      "metadata": {
        "id": "RYZ-FJgb85e-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gru8RyP49LkF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}